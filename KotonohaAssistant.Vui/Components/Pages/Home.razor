@page "/"
@rendermode InteractiveServer
@implements IDisposable
@using System.Text.RegularExpressions
@using KotonohaAssistant.AI.Functions
@using KotonohaAssistant.AI.Services
@using KotonohaAssistant.Core
@using KotonohaAssistant.Core.Utils
@using Toolbelt.Blazor.SpeechRecognition
@inject SpeechRecognition SpeechRecognition
@inject ConversationService ConversationService
@inject IAlarmService AlarmService
@inject IJSRuntime JS

<PageTitle>Kotonoha Assistant</PageTitle>

<div style="width: 95%; position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%);">
    <div id="conversationContainer" style="height: 700px;">
        @foreach (var (text, talking, function) in _messages)
        {
            if (function is not null)
            {
                var arguments = string.Join(", ", function.Arguments.Select(a => $"{a.Key}={a.Value}") ?? []);

                <div style="display: flex; justify-content: center;">
                    <div style="width: 400px; background: whitesmoke; color: #adadad; padding: 5px 20px 5px; margin: 5px 0px">
                        <details>
                            <summary>
                                @(function.Name)(@(arguments))
                            </summary>
                            <p style="white-space: pre-line">
                                @(function.Result)
                            </p>
                        </details>
                    </div>
                </div>
            }
            else if (talking == Kotonoha.Akane)
            {
                <div style="display: flex; justify-content: flex-start;">
                    <div style="width: 400px; margin: 7px 0px; padding: 0px 20px; border-radius: 20px 0px 20px 20px; background-color: pink;">
                        <p>@(text)</p>
                    </div>
                </div>
            }
            else if (talking == Kotonoha.Aoi)
            {
                <div style="display: flex; justify-content: flex-end;">
                    <div style="width: 400px; margin: 7px 0px; padding: 0px 20px; border-radius: 0px 20px 20px 20px; background-color: lightblue;">
                        <p>@(text)</p>
                    </div>
                </div>
            }
            else
            {
                <div style="display: flex; justify-content: center;">
                    <div style="width: 400px; background: whitesmoke; color: #adadad; padding: 5px 20px 5px; margin: 5px 0px">
                        <details>
                            <summary>
                                入力
                            </summary>
                            @text
                        </details>
                    </div>
                </div>
            }
        }
    </div>
</div>

<div style="position: fixed; bottom: 1.5em; left: 1em; width: 100%;">
    @if(_isMyTurn)
    {
        <p style="color: gray;">
            &gt;&nbsp;
            @(_talkingText)
            @if (_isInConversation)
            {
                <span class="blinking-underscore">_</span>
            }
        </p>
    }
    @if(_isThinking)
    {
        <p style="color: gray;">
            Thinking...
        </p>
    }
</div>

@code {
    /// <summary>
    /// 自分の番かどうか
    /// </summary>
    private bool _isMyTurn = true;

    /// <summary>
    /// 会話中かどうか
    /// </summary>
    private bool _isInConversation = false;

    /// <summary>
    /// 入力中のメッセージ
    /// </summary>
    private string _talkingText = "";

    /// <summary>
    /// 生成待ちフラグ
    /// </summary>
    private bool _isThinking = false;

    /// <summary>
    /// 会話履歴
    /// </summary>
    private readonly List<(string? text, Kotonoha? talking, ConversationFunction? function)> _messages = new();

    /// <summary>
    /// 会話終了タイムアウト用
    /// </summary>
    private CancellationTokenSource? _conversationTimer;

    /// <summary>
    /// 音声読み上げクライアント
    /// </summary>
    private VoiceClient? _voiceClient = null;

    protected override async Task OnInitializedAsync()
    {
        this.SpeechRecognition.Lang = "ja-JP";
        this.SpeechRecognition.InterimResults = true;
        this.SpeechRecognition.Continuous = true;
        this.SpeechRecognition.Result += OnSpeechRecognized;
        this.SpeechRecognition.End += OnSpeechEnded;
        _ = this.SpeechRecognition.StartAsync();

        _voiceClient = new VoiceClient();

        await ConversationService.LoadLatestConversation();
        foreach (var (sister, message) in ConversationService.GetAllMessages())
        {
            _messages.Add((message, sister, null));
        }

        this.StateHasChanged();
        ScrollToEnd();
    }

    private void OnSpeechRecognized(object? sender, SpeechRecognitionEventArgs args)
    {
        // 琴葉姉妹の会話中は受け付けない
        if (!_isMyTurn)
        {
            return;
        }

        var lastResult = args?.Results?.LastOrDefault();
        if (lastResult is null)
        {
            return;
        }

        // 一言でも喋ると会話終了タイムアウトをリセットする
        ResetConversationTimeout();

        var transcript = lastResult.Items?[0].Transcript;
        if (transcript is null)
        {
            return;
        }

        transcript = ReplaceFuzzyMatchWord(transcript);

        _talkingText = transcript;
        this.StateHasChanged();

        // こちらの入力がまだ終わっていない場合
        if (!lastResult.IsFinal)
        {
            return;
        }

        // 特定の単語で会話を終了
        if (_isInConversation && IsStopWord(transcript))
        {
            _isInConversation = false;
            StateHasChanged();
            return;
        }

        // ウェイクワードが含まれていたら会話開始

        if (ContainsWakeWord(transcript))
        {
            _isInConversation = true;
        }

        // 会話中の入力はすべて送信する
        if (_isInConversation)
        {
            _messages.Add((transcript, null, null));

            _ = SendMessage(transcript);
        }

        string ReplaceFuzzyMatchWord(string input)
        {
            input = Regex.Replace(input, Settings.FuzzyMatchAkane.From, Settings.FuzzyMatchAkane.To);
            input = Regex.Replace(input, Settings.FuzzyMatchAoi.From, Settings.FuzzyMatchAoi.To);
            return input;
        }

        bool ContainsWakeWord(string? text)
        {
            if (string.IsNullOrWhiteSpace(text))
            {
                return false;
            }

            var removed = Regex.Replace(text, @"[、。？?\s]", string.Empty);
            return Settings.WakeWords.Any(word => removed.Contains(word));
        }

        bool IsStopWord(string? text)
        {
            if (string.IsNullOrWhiteSpace(text))
            {
                return false;
            }

            var removed = text.TrimEnd('。');
            return Settings.StopWords.Any(word => word == text);
        }
    }

    /// <summary>
    /// メッセージの生成＆読み上げ
    /// </summary>
    /// <param name="message"></param>
    /// <returns></returns>
    private async Task SendMessage(string message)
    {
        if (ConversationService is null || _voiceClient is null)
        {
            return;
        }

        _isMyTurn = false;
        _isThinking = true;
        this.StateHasChanged();
        await this.SpeechRecognition.StopAsync();

        // アラーム停止
        AlarmService.StopAlarm();

        ScrollToEnd();

        var forgotten = false;
        await foreach (var result in ConversationService.TalkWithKotonohaSisters(message))
        {
            // 関数呼び出しがあった場合は個別に表示
            if (result.Functions is not null)
            {
                foreach (var function in result.Functions)
                {
                    _messages.Add(((string?)null, (Kotonoha?)null, function));
                }

                if (result.Functions.Any(f => f.Name == nameof(ForgetMemory) && f.Result == ForgetMemory.SuccessMessage))
                {
                    forgotten = true;
                }
            }

            _messages.Add((result.Message, result.Sister, null));

            _isThinking = false;
            this.StateHasChanged();

            ScrollToEnd();

            // 読み上げ
            await _voiceClient.SpeakAsync(result.Sister, result.Emotion, result.Message);

            _isThinking = true;
            this.StateHasChanged();

            ScrollToEnd();
        }

        await this.SpeechRecognition.StartAsync();

        _isThinking = false;
        _isMyTurn = true;
        _talkingText = "";
        if (forgotten)
        {
            _messages.Clear();
        }
        this.StateHasChanged();

        ScrollToEnd();
        StartConversationTimeout(Settings.CoversationTimeout);
    }

    /// <summary>
    /// 指定した時間経過すると会話を終了する
    /// </summary>
    private void StartConversationTimeout(int interval)
    {
        _conversationTimer?.Cancel(); // 前のタイマーをキャンセル
        _conversationTimer = new CancellationTokenSource();
        var token = _conversationTimer.Token;

        Task.Delay(interval, token).ContinueWith(t =>
        {
            if (!token.IsCancellationRequested)
            {
                _isInConversation = false; // 指定時間経過後に会話終了
                StateHasChanged();
            }
        }, TaskScheduler.FromCurrentSynchronizationContext());
    }

    private void OnSpeechEnded(object? sender, EventArgs args)
    {
        // 一定時間入力がないと音声認識が停止するのでそのたびに起動
        if (!_isInConversation)
        {
            try
            {
                _ = this.SpeechRecognition.StartAsync();
            }
            catch (Exception)
            {
                // すでに起動済みの場合の例外は無視
            }
        }
    }

    /// <summary>
    /// 会話終了のタイムアウトをリセットする
    /// </summary>
    private void ResetConversationTimeout()
    {
        _conversationTimer?.Cancel(); // 前のタイマーをキャンセル
        _conversationTimer = new CancellationTokenSource();
    }

    public void Dispose()
    {
        this.SpeechRecognition.Result -= OnSpeechRecognized;
        this.SpeechRecognition.End -= OnSpeechEnded;
        _voiceClient?.Dispose();
        _conversationTimer?.Cancel();
    }

    private void ScrollToEnd()
    {
        _ = JS.InvokeVoidAsync("scrollToEnd", new object[] { "conversationContainer" });
    }
}
